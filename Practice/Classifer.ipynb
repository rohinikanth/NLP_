{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Naive bayes classifier"
      ],
      "metadata": {
        "id": "915tCGblrxGh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "aL4m8WYIoZh-",
        "outputId": "21433afb-a747-40cb-f018-383327266eac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Bad'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text  import TfidfVectorizer\n",
        "#from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "texts = [\"I love this product!\", \"This is terrible and disappointing.\", \"I feel so happy today!\", \"I am extremely sad.\"]\n",
        "labels = [1, 0, 1, 0]\n",
        "\n",
        "vector=TfidfVectorizer()\n",
        "X= vector.fit_transform(texts)\n",
        "\n",
        "model = MultinomialNB()\n",
        "model.fit(X,labels)\n",
        "\n",
        "\n",
        "def predict_sentiment(texts):\n",
        "    Inp = vector.transform([texts])\n",
        "    prediction=model.predict(Inp)\n",
        "\n",
        "    print(Inp.toarray())\n",
        "    if prediction[0]==1:\n",
        "      return (\"Good\")\n",
        "    else:\n",
        "      return (\"Bad\")\n",
        "\n",
        "predict_sentiment(\"Iam sad\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_sentiment(\"i like ice\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "0SuzgRoWrpHF",
        "outputId": "46ddcdf0-c626-40d1-9c08-5dbc43dc9686"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Bad'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_sentiment(\"Iam dissaapoint\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "aXWnZpblrvuu",
        "outputId": "f3603bd4-01bb-46bf-e48e-651b7a3b372f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Bad'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bag of words"
      ],
      "metadata": {
        "id": "0RRhuyJfsHDC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text  import TfidfVectorizer\n",
        "texts = [\"I love this product!\", \"This is terrible and disappointing.\", \"I feel so happy today!\", \"I am extremely sad.\"]\n",
        "\n",
        "vector=CountVectorizer()\n",
        "vector2=TfidfVectorizer()\n",
        "\n",
        "X=vector.fit_transform(texts)\n",
        "\n",
        "print(vector.vocabulary_)\n",
        "print(vector2.analyzer)\n",
        "print(\"Bag of words vector:\",X.toarray(),end='')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTNzUYYAsF2q",
        "outputId": "f9eafe2e-e9c1-4b27-bec9-dae9f3583145"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'love': 7, 'this': 12, 'product': 8, 'is': 6, 'terrible': 11, 'and': 1, 'disappointing': 2, 'feel': 4, 'so': 10, 'happy': 5, 'today': 13, 'am': 0, 'extremely': 3, 'sad': 9}\n",
            "word\n",
            "Bag of words vector: [[0 0 0 0 0 0 0 1 1 0 0 0 1 0]\n",
            " [0 1 1 0 0 0 1 0 0 0 0 1 1 0]\n",
            " [0 0 0 0 1 1 0 0 0 0 1 0 0 1]\n",
            " [1 0 0 1 0 0 0 0 0 1 0 0 0 0]]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "\n",
        "text = \"Hello!!! How are you? NLP is @exciting, isn't it?\"\n",
        "clean_text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "print(\"Text without Punctuation:\", clean_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWppvycEHOu8",
        "outputId": "bb0dea6d-4a8b-4aa8-9168-e4fbdb98c8c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text without Punctuation: Hello How are you NLP is exciting isnt it\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "text = \"Python & NLP are great!! But, should we keep@ hyphens - like this?\"\n",
        "re.sub(r'[^a-zA-Z0-9\\s@-]', '', text)  # Keeps words, spaces, and hyphens\n",
        "\n",
        "#print(\"Custom Cleaned Text:\", clean_text)\n",
        "#clean_text ="
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "dUqV6WGpJsVY",
        "outputId": "c3211295-0b96-4d63-f0aa-797fc84f9aa9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Python  NLP are great But should we keep@ hyphens - like this'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "my1hwt2FJFw6",
        "outputId": "f93f543f-9b14-450d-b5d7-6d905bea6dd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "text = [\"Hey there! NLP @2024 is awesome.\", \" Let's remove #special_chars & punctuations!\"]\n",
        "clean_tokens=[]\n",
        "for sent in text:\n",
        "  tokens = word_tokenize(sent)\n",
        "\n",
        "\n",
        "  for word in tokens:\n",
        "    if word.isalnum():\n",
        "      clean_tokens.append(word)  # Keep only alphanumeric words\n",
        "clean_text = \" \".join(clean_tokens)\n",
        "\n",
        "\n",
        "print(\"Cleaned Text:\", clean_text)\n",
        "\n",
        "clean_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRLLZEHYIlgY",
        "outputId": "ce90c4e0-248b-4fc5-83cf-f00ab28a740f",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned Text: Hey there NLP 2024 is awesome Let remove punctuations\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hey',\n",
              " 'there',\n",
              " 'NLP',\n",
              " '2024',\n",
              " 'is',\n",
              " 'awesome',\n",
              " 'Let',\n",
              " 'remove',\n",
              " 'punctuations']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "text = \"Hey there! NLP @2024 is awesome. Let's remove #special_chars & punctuations!\"\n",
        "tokens = word_tokenize(text)\n",
        "\n",
        "clean_tokens = []  # Initialize an empty list to store cleaned words\n",
        "\n",
        "for word in tokens:\n",
        "    if word.isalnum():  # Keep only alphanumeric words\n",
        "        clean_tokens.append(word)\n",
        "\n",
        "clean_text = \" \".join(clean_tokens)  # Join words to form cleaned text\n",
        "\n",
        "print(\"Cleaned Text:\", clean_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gn2CS3jKAOR",
        "outputId": "0bf26141-0e74-4d9b-ef12-1baa56512e02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned Text: Hey there NLP 2024 is awesome Let remove punctuations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Hey there! NLP @2024 is awesome. Let's remove #special_chars & punctuations!\"\n",
        "tokens=[text.split()]\n",
        "\n",
        "for word in tokens:\n",
        "    if word.isalnum():  # Keep only alphanumeric words\n",
        "        clean_tokens.append(word)"
      ],
      "metadata": {
        "id": "0Eb115vh9_WR"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}